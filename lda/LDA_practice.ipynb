{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer    \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for line in open('test.txt', 'r').readlines():\n",
    "    corpus.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t新春 备 年货 ， 新年 联欢晚会\n",
      "1\t新春 节目单 ， 春节 联欢晚会 红火\n",
      "2\t大盘 下跌 股市 散户\n",
      "3\t下跌 股市 赚钱\n",
      "4\t金猴 新春 红火 新年\n",
      "5\t新车 新年 年货 新春\n",
      "6\t股市 反弹 下跌\n",
      "7\t股市 散户 赚钱\n",
      "8\t新年 , 看 春节 联欢晚会\n",
      "9\t大盘 下跌 散户\n"
     ]
    }
   ],
   "source": [
    "for i, cor in enumerate(corpus):\n",
    "    print('{}\\t{}'.format(i, cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将语料转换为词频矩阵，矩阵元素a[i][j]表示文档i中词j的词频\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# 获取词袋模型中的所有词语\n",
    "vocab = vectorizer.get_feature_names()\n",
    "weight = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:\n",
      " ['下跌', '反弹', '大盘', '年货', '散户', '新年', '新春', '新车', '春节', '红火', '联欢晚会', '股市', '节目单', '赚钱', '金猴']\n",
      "\n",
      "word freq matrix:\n",
      " [[0 0 0 1 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 1 1 0 1 0 0]\n",
      " [1 0 1 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 1 0 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      " [1 0 1 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('vocab:\\n {}\\n'.format(vocab))\n",
    "print('word freq matrix:\\n {}\\n'.format(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 训练模型\n",
    "其中设置2个主题，500次迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 10\n",
      "INFO:lda:vocab_size: 15\n",
      "INFO:lda:n_words: 36\n",
      "INFO:lda:n_topics: 2\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -192\n",
      "INFO:lda:<10> log likelihood: -140\n",
      "INFO:lda:<20> log likelihood: -133\n",
      "INFO:lda:<30> log likelihood: -133\n",
      "INFO:lda:<40> log likelihood: -133\n",
      "INFO:lda:<50> log likelihood: -133\n",
      "INFO:lda:<60> log likelihood: -133\n",
      "INFO:lda:<70> log likelihood: -133\n",
      "INFO:lda:<80> log likelihood: -137\n",
      "INFO:lda:<90> log likelihood: -133\n",
      "INFO:lda:<100> log likelihood: -133\n",
      "INFO:lda:<110> log likelihood: -133\n",
      "INFO:lda:<120> log likelihood: -133\n",
      "INFO:lda:<130> log likelihood: -133\n",
      "INFO:lda:<140> log likelihood: -133\n",
      "INFO:lda:<150> log likelihood: -133\n",
      "INFO:lda:<160> log likelihood: -133\n",
      "INFO:lda:<170> log likelihood: -133\n",
      "INFO:lda:<180> log likelihood: -133\n",
      "INFO:lda:<190> log likelihood: -133\n",
      "INFO:lda:<200> log likelihood: -133\n",
      "INFO:lda:<210> log likelihood: -133\n",
      "INFO:lda:<220> log likelihood: -133\n",
      "INFO:lda:<230> log likelihood: -133\n",
      "INFO:lda:<240> log likelihood: -133\n",
      "INFO:lda:<250> log likelihood: -133\n",
      "INFO:lda:<260> log likelihood: -133\n",
      "INFO:lda:<270> log likelihood: -133\n",
      "INFO:lda:<280> log likelihood: -133\n",
      "INFO:lda:<290> log likelihood: -133\n",
      "INFO:lda:<300> log likelihood: -133\n",
      "INFO:lda:<310> log likelihood: -133\n",
      "INFO:lda:<320> log likelihood: -133\n",
      "INFO:lda:<330> log likelihood: -133\n",
      "INFO:lda:<340> log likelihood: -133\n",
      "INFO:lda:<350> log likelihood: -133\n",
      "INFO:lda:<360> log likelihood: -133\n",
      "INFO:lda:<370> log likelihood: -133\n",
      "INFO:lda:<380> log likelihood: -133\n",
      "INFO:lda:<390> log likelihood: -133\n",
      "INFO:lda:<400> log likelihood: -133\n",
      "INFO:lda:<410> log likelihood: -133\n",
      "INFO:lda:<420> log likelihood: -133\n",
      "INFO:lda:<430> log likelihood: -133\n",
      "INFO:lda:<440> log likelihood: -133\n",
      "INFO:lda:<450> log likelihood: -137\n",
      "INFO:lda:<460> log likelihood: -133\n",
      "INFO:lda:<470> log likelihood: -133\n",
      "INFO:lda:<480> log likelihood: -133\n",
      "INFO:lda:<490> log likelihood: -133\n",
      "INFO:lda:<499> log likelihood: -133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7eff016672b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=2, n_iter=500, random_state=1)\n",
    "model.fit(np.asarray(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 主题 - 单词（topic-word）分布\n",
    "\n",
    "计算vocab[:3]==> 下跌、反弹、大盘 这三个单词在两个topic中的比重。\n",
    "\n",
    "可以看到下跌、反弹、大盘等股市主题词汇在主题1中的比重更大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['下跌', '反弹', '大盘']\n",
      "\n",
      "topic_word shape: (2, 15)\n",
      "\n",
      "[[ 0.00049628  0.00049628  0.00049628]\n",
      " [ 0.24829721  0.0625387   0.1244582 ]]\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_\n",
    "print('words: {}\\n'.format(vocab[:3]))\n",
    "print('topic_word shape: {}\\n'.format(topic_word.shape))\n",
    "print(topic_word[:, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算每个主题中比重最大的前5个词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['下跌' '反弹' '大盘' '散户' '股市']\n",
      "['年货' '新年' '新春' '新车' '春节']\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:n]\n",
    "    print(topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 文档 - 主题（document-topic）分布\n",
    "\n",
    "计算前三篇文档在两个topic中的比重。\n",
    "\n",
    "前三篇文档分别为：\n",
    "- [春节] 新春 备 年货 ， 新年 联欢晚会\n",
    "- [春节] 新春 节目单 ， 春节 联欢晚会 红火\n",
    "- [股市] 大盘 下跌 股市 散户\n",
    "\n",
    "可以看到第一篇和第二篇文档在主题0[春节]的比重大，第三篇文档在主题1[股市]的比重大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  新春 备 年货 ， 新年 联欢晚会\t\n",
      "1  新春 节目单 ， 春节 联欢晚会 红火\t\n",
      "2  大盘 下跌 股市 散户\t\n",
      "\n",
      "\n",
      "doc_topic shape: (10, 2)\n",
      "[[ 0.97619048  0.02380952]\n",
      " [ 0.98076923  0.01923077]\n",
      " [ 0.02380952  0.97619048]]\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "for i, cor in enumerate(corpus[:3]):\n",
    "    print('{}  {}\\t'.format(i, cor))\n",
    "print('\\n')\n",
    "print('doc_topic shape: {}'.format(doc_topic.shape))\n",
    "print(doc_topic[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
